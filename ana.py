# -*- coding: utf-8 -*-
"""Ana.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1shdANlfZ7CFPXdWdDuiQ5d_Duxlm206l
"""

import zipfile

# specify the path to the zip file in your Google Drive
zip_path = '/content/drive/MyDrive/dataset.zip'

# specify the path to the folder where you want to unzip the dataset
extract_path = '/content/dataset/'

# extract the contents of the zip file to the extract_path folder
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

import tensorflow as tf
from tensorflow import keras
from keras.layers import Dense, Rescaling, Conv2D, MaxPooling2D, Dropout, Flatten
from keras.callbacks import EarlyStopping
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import os
from keras.preprocessing.image import ImageDataGenerator
from google.colab import drive

# DATA SOURCE -----------------------------------------

batch_size = 25

train_data_dir = r'/content/dataset/dataset/training_set'
validation_data_dir = r'/content/dataset/dataset/test_set'

train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=15,
        zoom_range=0.1
)

validation_datagen = ImageDataGenerator(
        rescale=1./255
)

train_generator = train_datagen.flow_from_directory(
        train_data_dir,
        target_size=(150, 150),
        batch_size=batch_size,
        class_mode='categorical')

validation_generator = validation_datagen.flow_from_directory(
        validation_data_dir,
        target_size=(150, 150),
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=False)

model.to_json()

#IA GOOGLE

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions

model_transfer = VGG16(weights='imagenet', include_top=True)

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions

model_transfer = VGG16(weights='imagenet', include_top=True)
base_model = keras.applications.VGG16(
    weights='imagenet',
    input_shape=(150, 150, 3),
    include_top=False)

base_model.trainable = False

inputs = keras.Input(shape=(150, 150, 3))

x = base_model(inputs, training=False)
x = keras.layers.GlobalAveragePooling2D()(x)

x = keras.layers.Dense(256, activation='relu')(x)
outputs = keras.layers.Dense(2, activation='softmax')(x)

model_transfer = keras.Model(inputs, outputs)

model_transfer.compile(loss=tf.keras.losses.categorical_crossentropy,
                      optimizer=tf.keras.optimizers.Adam(1e-3),
                      metrics=['accuracy'])

epochs = 5

es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10, restore_best_weights=True)

h = model_transfer.fit(
        train_generator,
        epochs=epochs, 
        validation_data=validation_generator,
        callbacks = [es]
)

img = keras.preprocessing.image.load_img(
    r'/content/dataset/dataset/test_set/cats/cat.4061.jpg', target_size=(250,250)
)
img_array = keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0) 

predictions = model_transfer.predict(img_array)
predictions_transfer = model_transfer.predict(img_array)

print(train_generator.class_indices)
print(np.argmax(predictions[0]))
print(np.argmax(predictions_transfer[0]))

# EVALUATION ------------------------------------------

plt.plot(h.history['accuracy'])
plt.plot(h.history['val_accuracy'])
plt.plot(h.history['loss'])
plt.title('Model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training', 'validation','loss'], loc='upper right')
plt.show()

# TRANSFER-LEARNING RESULTS ---------------------------

total_val_samples = validation_generator.n
print("El generador de validación tiene", total_val_samples, "imágenes")

steps = total_val_samples // batch_size

results = np.concatenate([(y, model_transfer.predict(x=x)) for x, y in validation_generator], axis=1, steps=steps)

predictions = np.argmax(results[0], axis=1)
labels = np.argmax(results[1], axis=1)

cf_matrix = confusion_matrix(labels, predictions)

sns.heatmap(cf_matrix, annot=True, fmt="d", cmap="Blues")

print(classification_report(labels, predictions, digits = 4))